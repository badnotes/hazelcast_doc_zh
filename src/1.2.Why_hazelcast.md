为什么要用 Hazelcast？
--------

### 先看看传统的数据持久方案

在传统的是软件系统构架中数据根本，然后提供数据的持久化存储和接入数据的接口。基本上，应用程序接入的数据库只是另一台机器上的备份而已。为了提高传统体系结构的性能，需要提供一个更快的机器或者优化调整当前的应用资源。这将增加大量的人力和财力。

不过，有个想法是保持数据的副本放在非常靠近数据库的地方。这可以用外部的键值对存储器或者二级缓存来实现。目的是保护数据库过度荷载。然而，当数据库已经达到最大负载时，应用程序仍然执行存储(put)操作，这几乎是无效的，这种情形会使得数据库只能提供获取(get)操作。即使应用程序严格执行获取操作，仍然可能会出现一致性问题：当数据库内部改变了数据，如何实时的反应在本地缓存数据呢，如何抓住这些更改？这就像 TTL (time-to-live) 的概念或者直写式的解决方案。

然而，缓存数据用TTL的时候，如果频繁的接入相应的数据且时间小于TTL值，这将再一次获取到无效数据，另一方面，数据放在缓存而不用TTL的时候，如果有多个缓存集群，这样我们再一次在他们之间碰到了一致性问题，这可以通过节点间相互通信告知失效的数据来避免。

我们可以得出这样一个结论:一个结合了TTL和写功能的理想的缓存。而且,在这领域已经有几种缓存服务器和内存数据库解决方案。然而,这些都是通过其他技术在一定程度上提供独立的单个实例分配机制。这样我们又回到了起点:如果产品是单个实例或没有提供分布式的一致性我们将面临负载极限或容量问题。

### 再来看看Hazelcast

Hazelcast,一个全新的接近数据的方法，是围绕分布式来设计的。数据灵活和高效的共享给周围的集群.它是一个可集群和高扩展性的用于数据分发的内存数据网格系统。

Hazelcast的一个主要特征是没有主节点，集群中的每个节点配置为相同的功能。老的节点管理集群成员，自动的执行数据分发到其他节点。

另一个主要特征就是数据完全持久化在内存中.这是非常快的.万一失败了，比如一个节点崩溃了，也不会有数据丢失。因为Hazelcast集群中每一个节点都有一份数据副本。

在 Hazelcast的概述部分可以看到他的特性列表。Hazelcast支持多个分布式集合和特性。可以从各种不同的来源加载不同结构的数据,可以将消息发送到一个集群中,并发操作中可以使用锁，还可以监听一个集群里面的事件。

### Hazelcast独特优势

* 开源
* 仅一个很小的jar包，不需要安装软件
* 仅仅是一个库，并非框架
* 它提供了开箱即用的分布式数据结构(i.e. Map, Queue, MultiMap, Topic, Lock, Executor, etc.)
* 集群中并没有主节点，其中每个节点配置为在功能上是一样的
* 当存储在内存中和正在处理的数据增加时,只需增加有足够内存和处理能力的节点到集群
* 数据并不是唯一一份，而是分布式备份的。可以注意到,这是一个很大的好处,当集群中的一个节点(例如崩溃)数据也不会丢失。
* 节点间是互通的，并不像传统的键值缓存解决方案
* 如果你不满意他提供的方法,你还可以实现它的接口，把它作为一个平台来构建自己的分布式数据系统

它还在进化。Hazelcast具有一种动态开源社区,使其不断发展。

作为一个内存数据网格提供者,Hazelcast可以用在:

* 对于需要大数据的数据分析应用程序处理多个分区的数据,
* 频繁访问网格中的数据,
* 对性能、可伸缩性和低延迟有高要求的应用程序,
* 应用程序之间发布/订阅通信,
* 应用程序运行在分布式和可伸缩的云环境中,
* 一个高可用分布式缓存的应用程序,
* Coherence,Gemfire和Terracotta 的替代产品
